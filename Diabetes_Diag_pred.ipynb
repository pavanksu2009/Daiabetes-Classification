{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Telecom Customer Churn Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Matplotlib for visualization\n",
    "from matplotlib import pyplot as plt\n",
    "# display plots in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Seaborn for easier visualization\n",
    "import seaborn as sns\n",
    "\n",
    "# # scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder, LabelBinarizer\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Function for creating model pipelines - imblearn\n",
    "from imblearn.pipeline import make_pipeline as imbl_pipe\n",
    "\n",
    "# # Over-sampling using SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Classification metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Analytical Base Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe dimensions: (768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>test</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672000</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preg   plas  pres  skin   test  mass      pedi   age  class\n",
       "0   6.0  148.0  72.0  35.0   30.5  33.6  0.627000  50.0      1\n",
       "1   1.0   85.0  66.0  29.0   30.5  26.6  0.351000  31.0      0\n",
       "2   8.0  183.0  64.0  23.0   30.5  23.3  0.672000  32.0      1\n",
       "3   1.0   89.0  66.0  23.0   94.0  28.1  0.167000  21.0      0\n",
       "4   0.0  137.0  40.0  35.0  168.0  43.1  0.471876  33.0      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./Resources/Analytical_Base_Table.csv\")\n",
    "print(f\"Dataframe dimensions: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   preg    768 non-null    float64\n",
      " 1   plas    768 non-null    float64\n",
      " 2   pres    768 non-null    float64\n",
      " 3   skin    768 non-null    float64\n",
      " 4   test    768 non-null    float64\n",
      " 5   mass    768 non-null    float64\n",
      " 6   pedi    768 non-null    float64\n",
      " 7   age     768 non-null    float64\n",
      " 8   class   768 non-null    int64  \n",
      "dtypes: float64(8), int64(1)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate dataframe into separate object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 8) (768,)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop([\"class\"], axis=1)\n",
    "\n",
    "y = df[\"class\"]\n",
    "\n",
    "# display shapes of X and y\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537 231 537 231\n"
     ]
    }
   ],
   "source": [
    "random_state = 10\n",
    "\n",
    "# Split X and y into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n",
    "                                                    random_state=random_state)\n",
    "\n",
    "# Print number of observations in X_train, X_test, y_train, and y_test\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Saved Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = joblib.load('./models/challa_decision_tree.sav')\n",
    "knn_model = joblib.load('./models/challa_knn.sav')\n",
    "lr_model = joblib.load(\"./models/challa_logistic_regression.sav\")\n",
    "rf_model = joblib.load('./models/challa_random_forest.sav')\n",
    "xgb_model = joblib.load('./models/challa_XGBoost_model.sav')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dictionary `'models'`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models dictionary, it will be needed for ploting\n",
    "models = {\n",
    "    'dt' : 'Decision Tree',\n",
    "    'knn' : 'K-nearest Neighbors',\n",
    "    'lr' : 'Logistic Regression',\n",
    "    'rf' : 'Random Forest',\n",
    "    'xgb' : 'XGBoost'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dictionary `'loaded_models'`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of all loaded models\n",
    "loaded_models = {\n",
    "    'dt' : dt_model,\n",
    "    'knn': knn_model,\n",
    "    'lr' : lr_model,\n",
    "    'rf' : rf_model,\n",
    "    'xgb' : xgb_model\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'target_names' variable will be used later for printing evaluation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['Non-Diabetic', 'Diabetic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The function for creating the dataframe with evaluation metrics for each model.**\n",
    "\n",
    "<pre>input: loaded models dictionary\n",
    "output: evaluation metrics dataframe</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_test(fit_models):\n",
    "    lst = []\n",
    "    for name, model in fit_models.items():\n",
    "        pred = model.predict(X_test)\n",
    "        lst.append([name, \n",
    "                    precision_score(y_test, pred, average='macro'),\n",
    "                    recall_score(y_test, pred, average='macro'),\n",
    "                    f1_score(y_test, pred, average='macro'),\n",
    "                    accuracy_score(y_test, pred)])\n",
    "\n",
    "    eval_df = pd.DataFrame(lst, columns=['model', 'precision', 'recall', 'f1_macro', 'accuracy'])\n",
    "    eval_df.set_index('model', inplace = True)\n",
    "    return eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The helper function for displaying confusion matrix and classification report.**\n",
    "\n",
    "<pre>input: loaded models dictionary, models dictionary and a dictionary key for one of the models\n",
    "output: confusion matrix dataframe and classification report</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_rep_cm(fit_models, models, model_id):\n",
    "    # Predict classes using model_id\n",
    "    pred = fit_models[model_id].predict(X_test)\n",
    "    print()\n",
    "    print('\\t', models[model_id])\n",
    "    print('\\t', '='*len(models[model_id]))\n",
    "\n",
    "    # Display confusion matrix for y_test and pred\n",
    "    conf_df = pd.DataFrame(confusion_matrix(y_test, pred), columns=target_names, index=target_names)\n",
    "    conf_df.index.name = 'True Labels'\n",
    "    conf_df = conf_df.rename_axis('Predicted Labels', axis='columns')\n",
    "    display(conf_df)\n",
    "    \n",
    "    # Display classification report\n",
    "    print()\n",
    "    print(classification_report(y_test, pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_train(fit_models):\n",
    "    lst = []\n",
    "    for name, model in fit_models.items():\n",
    "        pred = model.predict(X_train)\n",
    "        lst.append([name, \n",
    "                    precision_score(y_train, pred, average='macro'),\n",
    "                    recall_score(y_train, pred, average='macro'),\n",
    "                    f1_score(y_train, pred, average='macro'),\n",
    "                    accuracy_score(y_train, pred)])\n",
    "\n",
    "    eval_df = pd.DataFrame(lst, columns=['model', 'precision', 'recall', 'f1_macro', 'accuracy'])\n",
    "    eval_df.set_index('model', inplace = True)\n",
    "    return eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>0.765367</td>\n",
       "      <td>0.784212</td>\n",
       "      <td>0.771506</td>\n",
       "      <td>0.787709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.739897</td>\n",
       "      <td>0.766986</td>\n",
       "      <td>0.740149</td>\n",
       "      <td>0.750466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.734242</td>\n",
       "      <td>0.750877</td>\n",
       "      <td>0.739437</td>\n",
       "      <td>0.757914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.827849</td>\n",
       "      <td>0.852241</td>\n",
       "      <td>0.835993</td>\n",
       "      <td>0.847300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>0.916278</td>\n",
       "      <td>0.937170</td>\n",
       "      <td>0.924924</td>\n",
       "      <td>0.931099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       precision    recall  f1_macro  accuracy\n",
       "model                                         \n",
       "dt      0.765367  0.784212  0.771506  0.787709\n",
       "knn     0.739897  0.766986  0.740149  0.750466\n",
       "lr      0.734242  0.750877  0.739437  0.757914\n",
       "rf      0.827849  0.852241  0.835993  0.847300\n",
       "xgb     0.916278  0.937170  0.924924  0.931099"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_train(loaded_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>0.732554</td>\n",
       "      <td>0.730364</td>\n",
       "      <td>0.731395</td>\n",
       "      <td>0.748918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.705763</td>\n",
       "      <td>0.715158</td>\n",
       "      <td>0.708021</td>\n",
       "      <td>0.718615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.721412</td>\n",
       "      <td>0.729047</td>\n",
       "      <td>0.724014</td>\n",
       "      <td>0.735931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.749847</td>\n",
       "      <td>0.761255</td>\n",
       "      <td>0.752941</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>0.732840</td>\n",
       "      <td>0.725814</td>\n",
       "      <td>0.728741</td>\n",
       "      <td>0.748918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       precision    recall  f1_macro  accuracy\n",
       "model                                         \n",
       "dt      0.732554  0.730364  0.731395  0.748918\n",
       "knn     0.705763  0.715158  0.708021  0.718615\n",
       "lr      0.721412  0.729047  0.724014  0.735931\n",
       "rf      0.749847  0.761255  0.752941  0.761905\n",
       "xgb     0.732840  0.725814  0.728741  0.748918"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_test(loaded_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_train_comp_df1 = evaluation_train(loaded_models)\n",
    "models_train_comp_df1 = models_train_comp_df1.reset_index().rename(columns={'model': 'Training_Set'})\n",
    "# models_train_comp_df1\n",
    "models_train_comp_df1.to_csv('Training_set_performance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_test_comp_df1 = evaluation_test(loaded_models)\n",
    "models_test_comp_df1 = models_test_comp_df1.reset_index().rename(columns={'model': 'Testing_Set'})\n",
    "# models_test_comp_df1\n",
    "models_test_comp_df1.to_csv('Testing_set_performance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During cross-validation we were trying two scorers, f1_macro and accuracy, and then used a model that had better recal for true positive (\"Exits\"). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display confusion matrix and classification report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Display classification report and confusion matrix for all models\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m models:\n\u001b[0;32m      4\u001b[0m     class_rep_cm(loaded_models, models, model)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "# Display classification report and confusion matrix for all models\n",
    "\n",
    "for model in models.keys():\n",
    "    class_rep_cm(loaded_models, models, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Description:**\n",
    "\n",
    "* The target variable is 'Churn'. It has a value of 1 for churn and 0 for not churn.\n",
    "* There are a lot of binary variables with 'Yes/No' values.\n",
    "* There are three continuous variables: tenure, monthly charges, and total charges.\n",
    "* The shape of the data is (6499,21)\n",
    "\n",
    "**Data Cleaning:**\n",
    "\n",
    "* The column 'Total_Charges' had 9 missing values. I have imputed the values with median of Total Charges\n",
    "* In the continuous variables, there are no outliers.\n",
    "\n",
    "**Key Observations from EDA:**\n",
    "\n",
    "* `Tenure`: The average tenure of customers with the company is around 32 months.\n",
    "* `Monthly_Charges`: Average monthly charges is 64.77 USD.\n",
    "* `Total_Charges`: Average total charges is 2282.94 USD. The distribution is skewed slightly to the right.\n",
    "* `Senior Citizen`: About 16% of customers are senior citizens.\n",
    "* `Dependents`: More than 70% of customers don't have dependents.\n",
    "* `Phone_Services`: More than 90% of customers have phone services enabled.\n",
    "* `Internet_Service`: 44% of customers use Fibre Optic for internet service. 34% use DSL, while the rest don't have internet services at all. \n",
    "* `Contract`: There are 55% customers with month-to-month contracts. Other two types of contract are: One-year and Two-year\n",
    "* `Payment_Method`: Electronic check is the most used payment method among the four methods of payment.\n",
    "* `Churn`: The churn rate in the data is about 26%.\n",
    "* `Churn vs Senior_Citizen`: Among Senior Citizen customers, the churn rate is about 41%. Senior Citizens are more likely to churn compare to others.\n",
    "* `Churn vs Internet_Service`: Among customers who don't use Internet Service, the churn rate is very low(8%). While, the churn rate is highest for Fibre Optic users(42%).\n",
    "* `Churn vs Contract`: As the length of contract increases, the likelihood of churning decreases. 43% of monthly contract customers are likely to churn, followed by 11% of one-year contracts, while two-year contract customers have the least churn rate of 3%\n",
    "* `Churn vs Payment_Method`: Customers with Electronic Check payment have a higher churn rate than any other payment method.\n",
    "* `Churn vs Tenure`: As tenure increases, the customers are less likely to churn. Customers with low tenure have churned the most.\n",
    "* `Churn vs Charges`: Customers who have churned, have higher monthly charges but lower total charges.\n",
    "* `Contract vs Internet_Service`: Among the month-to-month contract customers, the most used service for Internet is Fiber Optic. Among the one-year and two-year contract customers, DSL service is more used as compared to Fiber Optic.\n",
    "* `Contract vs Payment_Method`: Among the month-to-month contract customers, Electronic check method of payment is used extensively. Among the one-year and two-year contract customers, Credit Card and Bank transfer methods of payment are more used as compared to other methods\n",
    "* `Internet_Service vs Payment_Method`: Customers without internet service use the mailed check payment method the most. Customers with Fibre Optice internet service use the Electronic Check method the most.\n",
    "\n",
    "* In many other columns, like Online_Security, Online_Backup, Tech_Support, Streaming_Movies, etc. there is a level named 'No internet service'. Moreover, the count for the 'No internet service' level is also the same in all columns. This means that customers with No internet service don't have access to many other services like online security, streaming movies, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* K-Nearest Neighbors and Random Forest models overfit the data and is not able to generalise well.\n",
    "* The accuracies of Logistic Regression, Decision Tree and XGBoost models perform well in both training and test dataset.\n",
    "* Logistic Regression have given a generalised performance with high recall and high precision.\n",
    "* Overall, let's see what the precision and recall means in customer churn-\n",
    "\n",
    "**Precision** - Of all the customers that the algorithm predicts will churn, how many of them do actually churn?\n",
    "\n",
    "**Recall** – What percentage of customers that end up churning does the algorithm successfully find?\n",
    "\n",
    "Both precision and recall values are important for customer churn.\n",
    "\n",
    "High recall and low precision means the model is unnecessarily predicting non-churned customers as churned, adding overhead to the business.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The company should attract the customers likely to churn with bonus plans or discounts on recharges.\n",
    "* The company should improve Fiber optic internet services as its use is somehow increasing the probability of churn\n",
    "* The company should try to attract the newly joined customers with attractive offers so that they stay longer with the network. And also, try to make long-term contracts with the customers.\n",
    "* As per observations from the model, customers who use the internet to stream TV and movies have higher chances of churning than those who don't. This may be due to the poor internet connection faced by the customer. The company should improve the internet connectivity to check this.\n",
    "* Online Security and Tech Support should be provided to as many customers as possible"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('Diabetes-Classification-Ri9St7y4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "e6c85e3b5405eddcb28f14222d137248a0efd477ee81d42ce12f26367ca419b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
